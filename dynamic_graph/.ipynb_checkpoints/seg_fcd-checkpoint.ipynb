{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d51fc37-2867-408d-9418-276ac57da38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from comet_ml import Experiment\n",
    "\n",
    "# # Create an experiment with your api key\n",
    "# experiment = Experiment(\n",
    "#     api_key=\"4uUkmlOzv4WCej0LtoWtr5Pzj\",\n",
    "#     project_name=\"DGCNN_project_dl_bia\",\n",
    "#     workspace=\"nachinkin31\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672c60d8-8c11-4504-a8a9-221f5b8c05f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import precision_score, roc_auc_score\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5f5135-532a-449b-89e9-3adf6ed30b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment.add_tag(\"model with noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce55a15-f03e-46fc-8341-8c59981e3934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a6aa9b-dd89-4fd6-bc8e-5473b4084b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.fcd import *\n",
    "from utils.crop import get_loader_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275a305b-c033-4db8-aae6-39bc5d1bcb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07908363-dfac-44e7-ae10-538abd842a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "import torch\n",
    "\n",
    "import utils.data_processor as data_processor\n",
    "imp.reload(data_processor)\n",
    "from utils.data_processor import *\n",
    "\n",
    "import utils.visualization_tools as visualization_tools\n",
    "imp.reload(visualization_tools)\n",
    "from utils.visualization_tools import *\n",
    "\n",
    "import utils.metrics as metrics\n",
    "imp.reload(metrics)\n",
    "from utils.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53132cc0-b782-42e8-bdf2-6eecd2874b09",
   "metadata": {},
   "source": [
    "functions for loading and transforming data into point clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3168932-c3ed-4462-b728-4b3188f7ef82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_3dmaps_to_point_cloud_and_labels(brain, mask, size = 256):\n",
    "    \"\"\" \n",
    "    Transforms 3d tensors of brain and hippocampus into pointcloud and labels for it. Both only coordinates and \n",
    "    coordinates + intensity modes are suppoted\n",
    "      Args:\n",
    "          image_brain: torch tensor of size [size,size,size] with 1 at the positions with brain and 0 otherwise\n",
    "          image_hypo: torch tensor of size [size,size,size] with 1 at the positions with hippocampus and 0 otherwise\n",
    "          size: size of the input tensors along each direction, default = 256\n",
    "          seg: torch tensor of size [size,size,size] with intensities of brain, default None\n",
    "      Output:\n",
    "          torch tensor of size [N, 3] is seg is None and [N, 4] otherwise and [N,] tensor with labels\n",
    "      \"\"\"\n",
    "    if type(size) == int:\n",
    "        grid_x, grid_y, grid_z = torch.meshgrid(torch.tensor(range(size)),\\\n",
    "                                                torch.tensor(range(size)),\\\n",
    "                                                torch.tensor(range(size)))\n",
    "    else:\n",
    "        grid_x, grid_y, grid_z = torch.meshgrid(torch.tensor(range(size[0])),\\\n",
    "                                                torch.tensor(range(size[1])),\\\n",
    "                                                torch.tensor(range(size[2])))\n",
    "        \n",
    "    new = torch.cat((grid_x.unsqueeze(-1).float(), \n",
    "                     grid_y.unsqueeze(-1).float(),\n",
    "                     grid_z.unsqueeze(-1).float(), \n",
    "                     torch.tensor(brain).float().unsqueeze(-1).float()), -1)\n",
    "    pc_fcd = new[mask==1,:]\n",
    "    fcd_len = pc_fcd.shape[0]\n",
    "    idx = np.random.choice(range(fcd_len),fcd_len//100,replace = False)\n",
    "    pc_fcd = pc_fcd[idx]\n",
    "    \n",
    "    \n",
    "    pc_brain_without_fcd = new[(mask==0)*(brain != 0),:]\n",
    "    no_fcd_len = pc_brain_without_fcd.shape[0]\n",
    "    idx = np.random.choice(range(no_fcd_len),no_fcd_len//100,replace = False)\n",
    "    pc_brain_without_fcd = pc_brain_without_fcd[idx]\n",
    "    return torch.cat([pc_fcd,pc_brain_without_fcd]),\\\n",
    "np.array([1] * pc_fcd.shape[0] + [0] * pc_brain_without_fcd.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e98ff9-4fc3-497a-8ffd-2f74d88023df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcd_filename_to_pc_and_labels(file, file_mask, size = 256):\n",
    "    \"\"\" \n",
    "    Procceses filename of brain and mask into pointcloud with labels\n",
    "      Args:\n",
    "          file: path to brain file\n",
    "          file_mask: path to mask file\n",
    "          size: size of the input tensors along each direction is 256, but it can be maxpulled to size. Default = 256\n",
    "          segfile: file with segmentation path\n",
    "      Output:\n",
    "          torch tensor of size [N, 3] is seg is None and [N, 4] otherwise and [N,] tensor with labels\n",
    "      \"\"\"\n",
    "    \n",
    "    brain = load_nii_to_array(file)\n",
    "      \n",
    "    mask = load_nii_to_array(file_mask)\n",
    "    \n",
    "    pc,labels = binary_3dmaps_to_point_cloud_and_labels(brain, mask, size = size)\n",
    "    \n",
    "    return pc, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b1a517-005b-4606-8297-992eda9d9879",
   "metadata": {},
   "source": [
    "# Example of creation of Data for experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a21ab4-51e1-4fba-8cf4-837616f15e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = (316, 374, 309)\n",
    "UPSAMPLE_RATE = 10\n",
    "POSTFIX = '_exp1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbedfe87-3bd0-4363-9fe7-690afe5e3a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs, labels = [], []\n",
    "means_and_stds = []\n",
    "for file in tqdm(glob.glob('../pytorch/croped_new_dataset/fcd_brains/fcd_*1.nii.gz')):\n",
    "    peace = file.split('/')[-1]\n",
    "    try:\n",
    "        file_mask = glob.glob(f'../pytorch/croped_new_dataset/masks/mask_{peace}*')[0]\n",
    "    except Exception:\n",
    "        pass\n",
    "    pc, label = fcd_filename_to_pc_and_labels(file, file_mask,\n",
    "                                  size = SIZE)\n",
    "    pc = np.array(pc.detach(),dtype = float)\n",
    "    means_and_stds.append([pc.mean(0), pc.std(0)])\n",
    "    pcs.append(pc)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6da118-5f42-4572-a833-d7e944b2141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_labels = [np.array(0)]*len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7020b8-e049-4736-a732-68d034da3ad2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for e in tqdm(range(len(pcs))):\n",
    "    TEST_DATA_INDEXES = [e]\n",
    "    std = np.array([x[1] for x in (means_and_stds[:e] + means_and_stds[e+1:])]).mean(0)\n",
    "    mean = np.array([x[0] for x in (means_and_stds[:e] + means_and_stds[e+1:])]).mean(0)\n",
    "    pcs_test,labels_test, sc_labels_test = ([(pcs[i]-mean)/std for i in TEST_DATA_INDEXES]*UPSAMPLE_RATE,\n",
    "                                            [labels[i] for i in TEST_DATA_INDEXES]*UPSAMPLE_RATE,\n",
    "                                            [sc_labels[i] for i in TEST_DATA_INDEXES]*UPSAMPLE_RATE)\n",
    "    pcs_train,labels_train, sc_labels_train = ([(pcs[i]-mean)/std for i in range(len(pcs)) if i not in TEST_DATA_INDEXES]*UPSAMPLE_RATE,\\\n",
    "                                            [labels[i] for i in range(len(pcs)) if i not in TEST_DATA_INDEXES]*UPSAMPLE_RATE,\\\n",
    "                                            [sc_labels[i] for i in range(len(pcs)) if i not in TEST_DATA_INDEXES]*UPSAMPLE_RATE)\n",
    "    \n",
    "    data_test = (pcs_test,labels_test, sc_labels_test)\n",
    "    data_train = (pcs_train,labels_train, sc_labels_train)\n",
    "    with open(f'../pytorch/data/BrainData/test_data{POSTFIX}_{e}.pkl', 'wb') as f:\n",
    "        pickle.dump(data_test, f)\n",
    "    with open(f'../pytorch/data/BrainData/trainval_data{POSTFIX}_{e}.pkl', 'wb') as f:\n",
    "        pickle.dump(data_train, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c49efa-d0d7-4c15-bab7-fd53c7baae5c",
   "metadata": {},
   "source": [
    "### Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b25c6cb-694c-4c8b-8e6d-40bd5f7c4af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = PCDataset(pcs_train,labels_train, num_point_cloud=10000)\n",
    "test_data = PCDataset(pcs_test,labels_test, num_point_cloud=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395cb9b0-363a-4f8f-8046-104dfdbf5570",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25a821a-5b59-4b00-9757-7e2d51bcdf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DGCNN import DGCNN_semseg\n",
    "from train_eval import train_val, val_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fa9cbc-3ea2-4c62-bc69-0d69959ba579",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 0\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
    "torch.cuda.set_device(DEVICE)\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9952a1d9-888c-46cc-aaef-b8f2cfbc17d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_point_cloud = 20000\n",
    "n_epochs = 12\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ccf5f8-88ca-428b-ac65-c6f760012686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you use the pretrained model then uncommemt\n",
    "\n",
    "# path_to_model = \"models/dgcnn_new_dataset_noise.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511f76fb-e644-4bd1-97df-71375d0390ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add argument std to train_val and uncomment if you want to train the models with the noise \n",
    "\n",
    "#std = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6046fb43-737b-4a72-a7f2-c1e46ef8490c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
    "valloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3576c2c1-2952-4410-9761-8617728e5efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSTFIX = '_exp1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4347219e-9857-4d61-84f1-12594ff9f85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics to save\n",
    "result_dict = {\"BCE\": [], \"IoU\": [], \"ROC-AUC\": [], \"Dice\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e0172b-b6dc-42ff-883a-98b196ff1e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_model_to_save = \"models/probnik\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb183bd-6317-4e37-886c-83e9d8acb624",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for e in tqdm(range(len(pcs))):\n",
    "    print(\"-------------------------------------\")\n",
    "    print(f\"training on {POSTFIX}_{e}:\")\n",
    "    with open(f'../pytorch/data/BrainData/test_data{POSTFIX}_{e}.pkl', 'rb') as f:\n",
    "        pcs_test,labels_test,_ = pickle.load(f)\n",
    "    with open(f'../pytorch/data/BrainData/trainval_data{POSTFIX}_{e}.pkl', 'rb') as f:\n",
    "        pcs_train,labels_train,_ = pickle.load(f)\n",
    "    #creating dataset\n",
    "    train_data = PCDataset(pcs_train,labels_train, num_point_cloud)\n",
    "    test_data = PCDataset(pcs_test,labels_test, num_point_cloud)\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
    "    valloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
    "    \n",
    "    pos_frac = np.sum([np.sum(el == 1) for el in labels_train]) / np.sum([len(el) for el in labels_train])\n",
    "    pos_weight = torch.FloatTensor([(1 - pos_frac)/pos_frac]).to(device)\n",
    "    \n",
    "    model = DGCNN_semseg(k=20, emd_dims=512, dropout=0.5)\n",
    "    if path_to_model is not None:\n",
    "        model.load_state_dict(torch.load(path_to_model, map_location='cpu'))\n",
    "    model.to(device)\n",
    "    \n",
    "    opt = optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-4)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    \n",
    "    metrics_dict = train_val(model, opt, criterion, trainloader, valloader,\n",
    "                         n_epochs=n_epochs, is_train=True, val_step_func=val_step)\n",
    "    \n",
    "    result_dict[\"BCE_noise\"].append(metrics_dict[\"loss\"])\n",
    "    result_dict[\"IoU_noise\"].append(metrics_dict[\"iou\"])\n",
    "    result_dict[\"ROC-AUC_noise\"].append(metrics_dict[\"roc\"])\n",
    "    result_dict[\"Dice_noise\"].append(metrics_dict[\"dice\"])\n",
    "    \n",
    "    #path_to_save\n",
    "    path=os.path.join(dir_model_to_save, f\"dgcnn_{POSTFIX}_{e}.pth\")\n",
    "    torch.save(model.state_dict(), path)\n",
    "    del model\n",
    "    del train_data, test_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94350a3f-e3a9-4a82-a328-70df62a25e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pretrained = pd.DataFrame(result_dict, index=[f\"{POSTFIX}_{e}\" for e in range(len(pcs))])\n",
    "\n",
    "df_pretrained.to_csv(\"metrics/exmaple.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5db34f-eb19-49aa-9e9d-cf8e5be5d1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
