{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "import torch\n",
    "\n",
    "import utils.data_processor as data_processor\n",
    "imp.reload(data_processor)\n",
    "from utils.data_processor import *\n",
    "\n",
    "import utils.visualization_tools as visualization_tools\n",
    "imp.reload(visualization_tools)\n",
    "from utils.visualization_tools import *\n",
    "\n",
    "import utils.metrics as metrics\n",
    "imp.reload(metrics)\n",
    "from utils.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_3dmaps_to_point_cloud_and_labels(brain, mask, size = 256):\n",
    "    \"\"\" \n",
    "    Transforms 3d tensors of brain and hippocampus into pointcloud and labels for it. Both only coordinates and \n",
    "    coordinates + intensity modes are suppoted\n",
    "      Args:\n",
    "          image_brain: torch tensor of size [size,size,size] with 1 at the positions with brain and 0 otherwise\n",
    "          image_hypo: torch tensor of size [size,size,size] with 1 at the positions with hippocampus and 0 otherwise\n",
    "          size: size of the input tensors along each direction, default = 256\n",
    "          seg: torch tensor of size [size,size,size] with intensities of brain, default None\n",
    "      Output:\n",
    "          torch tensor of size [N, 3] is seg is None and [N, 4] otherwise and [N,] tensor with labels\n",
    "      \"\"\"\n",
    "    if type(size) == int:\n",
    "        grid_x, grid_y, grid_z = torch.meshgrid(torch.tensor(range(size)),\\\n",
    "                                                torch.tensor(range(size)),\\\n",
    "                                                torch.tensor(range(size)))\n",
    "    else:\n",
    "        grid_x, grid_y, grid_z = torch.meshgrid(torch.tensor(range(size[0])),\\\n",
    "                                                torch.tensor(range(size[1])),\\\n",
    "                                                torch.tensor(range(size[2])))\n",
    "        \n",
    "    new = torch.cat((grid_x.unsqueeze(-1).float(), \n",
    "                     grid_y.unsqueeze(-1).float(),\n",
    "                     grid_z.unsqueeze(-1).float(), \n",
    "                     torch.tensor(brain).float().unsqueeze(-1).float()), -1)\n",
    "    pc_fcd = new[mask==1,:]\n",
    "    fcd_len = pc_fcd.shape[0]\n",
    "    idx = np.random.choice(range(fcd_len),fcd_len//100,replace = False)\n",
    "    pc_fcd = pc_fcd[idx]\n",
    "    \n",
    "    \n",
    "    pc_brain_without_fcd = new[(mask==0)*(brain != 0),:]\n",
    "    no_fcd_len = pc_brain_without_fcd.shape[0]\n",
    "    idx = np.random.choice(range(no_fcd_len),no_fcd_len//100,replace = False)\n",
    "    pc_brain_without_fcd = pc_brain_without_fcd[idx]\n",
    "    return torch.cat([pc_fcd,pc_brain_without_fcd]),\\\n",
    "np.array([1] * pc_fcd.shape[0] + [0] * pc_brain_without_fcd.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcd_filename_to_pc_and_labels(file, file_mask, size = 256):\n",
    "    \"\"\" \n",
    "    Procceses filename of brain and mask into pointcloud with labels\n",
    "      Args:\n",
    "          file: path to brain file\n",
    "          file_mask: path to mask file\n",
    "          size: size of the input tensors along each direction is 256, but it can be maxpulled to size. Default = 256\n",
    "          segfile: file with segmentation path\n",
    "      Output:\n",
    "          torch tensor of size [N, 3] is seg is None and [N, 4] otherwise and [N,] tensor with labels\n",
    "      \"\"\"\n",
    "    \n",
    "    brain = load_nii_to_array(file)\n",
    "      \n",
    "    mask = load_nii_to_array(file_mask)\n",
    "    \n",
    "    pc,labels = binary_3dmaps_to_point_cloud_and_labels(brain, mask, size = size)\n",
    "    \n",
    "    return pc, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for experiment creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = (316, 374, 309)\n",
    "UPSAMPLE_RATE = 10\n",
    "POSTFIX = '_exp1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:58<00:00,  4.55s/it]\n"
     ]
    }
   ],
   "source": [
    "pcs, labels = [], []\n",
    "means_and_stds = []\n",
    "for file in tqdm(glob.glob('croped_new_dataset/fcd_brains/fcd_*1.nii.gz')):\n",
    "    peace = file.split('/')[-1]\n",
    "    try:\n",
    "        file_mask = glob.glob(f'croped_new_dataset/masks/mask_{peace}*')[0]\n",
    "    except Exception:\n",
    "        pass\n",
    "    pc, label = fcd_filename_to_pc_and_labels(file, file_mask, \n",
    "                                  size = SIZE)\n",
    "    pc = np.array(pc.detach(),dtype = float)\n",
    "    means_and_stds.append([pc.mean(0), pc.std(0)])\n",
    "    pcs.append(pc)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_labels = [np.array(0)]*len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:31<00:00,  1.21s/it]\n"
     ]
    }
   ],
   "source": [
    "for e in tqdm(range(len(pcs))):\n",
    "    TEST_DATA_INDEXES = [e]\n",
    "    std = np.array([x[1] for x in (means_and_stds[:e] + means_and_stds[e+1:])]).mean(0)\n",
    "    mean = np.array([x[0] for x in (means_and_stds[:e] + means_and_stds[e+1:])]).mean(0)\n",
    "    \n",
    "    pcs_test,labels_test, sc_labels_test = [(pcs[i]-mean)/std for i in TEST_DATA_INDEXES]*UPSAMPLE_RATE,\\\n",
    "                                            [labels[i] for i in TEST_DATA_INDEXES]*UPSAMPLE_RATE,\\ \n",
    "                                            [sc_labels[i] for i in TEST_DATA_INDEXES]*UPSAMPLE_RATE\n",
    "    pcs_train,labels_train, sc_labels_train = [(pcs[i]-mean)/std for i in range(len(pcs)) if i not in TEST_DATA_INDEXES]*UPSAMPLE_RATE,\\\n",
    "                                            [labels[i] for i in range(len(pcs)) if i not in TEST_DATA_INDEXES]*UPSAMPLE_RATE,\\\n",
    "                                            [sc_labels[i] for i in range(len(pcs)) if i not in TEST_DATA_INDEXES]*UPSAMPLE_RATE\n",
    "    \n",
    "    data_test = (pcs_test,labels_test, sc_labels_test)\n",
    "    data_train = (pcs_train,labels_train, sc_labels_train)\n",
    "    with open(f'data/BrainData/test_data{POSTFIX}_{e}.pkl', 'wb') as f:\n",
    "        pickle.dump(data_test, f)\n",
    "    with open(f'data/BrainData/trainval_data{POSTFIX}_{e}.pkl', 'wb') as f:\n",
    "        pickle.dump(data_train, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for pretraining on grey matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = (260, 311, 260)\n",
    "UPSAMPLE_RATE = 1\n",
    "POSTFIX = '_exp_grey'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_3dmaps_to_point_cloud_and_labels_grey(brain, seg, size = (260, 311, 260)):\n",
    "    \"\"\" \n",
    "    Transforms 3d tensors of brain and hippocampus into pointcloud and labels for it. Both only coordinates and \n",
    "    coordinates + intensity modes are suppoted\n",
    "      Args:\n",
    "          image_brain: torch tensor of size [size,size,size] with 1 at the positions with brain and 0 otherwise\n",
    "          image_hypo: torch tensor of size [size,size,size] with 1 at the positions with hippocampus and 0 otherwise\n",
    "          size: size of the input tensors along each direction, default = 256\n",
    "          seg: torch tensor of size [size,size,size] with intensities of brain, default None\n",
    "      Output:\n",
    "          torch tensor of size [N, 3] is seg is None and [N, 4] otherwise and [N,] tensor with labels\n",
    "      \"\"\"\n",
    "    grid_x, grid_y, grid_z = torch.meshgrid(torch.tensor(range(size[0])),\\\n",
    "                                            torch.tensor(range(size[1])),\\\n",
    "                                            torch.tensor(range(size[2])))\n",
    "    new = torch.cat((grid_x.unsqueeze(-1).float(), \n",
    "                     grid_y.unsqueeze(-1).float(),\n",
    "                     grid_z.unsqueeze(-1).float(), \n",
    "                     torch.tensor(brain).float().unsqueeze(-1).float()), -1)\n",
    "    pc_grey = new[seg>=1000,:]\n",
    "    grey_len = pc_grey.shape[0]\n",
    "    idx = np.random.choice(range(grey_len),grey_len//100,replace = False)\n",
    "    pc_grey = pc_grey[idx]\n",
    "    \n",
    "    \n",
    "    pc_brain_without_grey = new[(seg<1000)*(brain != 0),:]\n",
    "    no_grey_len = pc_brain_without_grey.shape[0]\n",
    "    idx = np.random.choice(range(no_grey_len),no_grey_len//100,replace = False)\n",
    "    pc_brain_without_grey = pc_brain_without_grey[idx]\n",
    "    return torch.cat([pc_grey,pc_brain_without_grey]),\\\n",
    "np.array([1] * pc_grey.shape[0] + [0] * pc_brain_without_grey.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grey_filename_to_pc_and_labels(intensity, segment, size = (260, 311, 260)):\n",
    "    \"\"\" \n",
    "    Procceses filename of brain and mask into pointcloud with labels\n",
    "      Args:\n",
    "          file: path to brain file\n",
    "          file_mask: path to mask file\n",
    "          size: size of the input tensors along each direction is 256, but it can be maxpulled to size. Default = 256\n",
    "          segfile: file with segmentation path\n",
    "      Output:\n",
    "          torch tensor of size [N, 3] is seg is None and [N, 4] otherwise and [N,] tensor with labels\n",
    "      \"\"\"\n",
    "    \n",
    "    brain = load_nii_to_array(intensity)\n",
    "      \n",
    "    seg = load_nii_to_array(segment)\n",
    "    \n",
    "    pc,labels = binary_3dmaps_to_point_cloud_and_labels_grey(brain, seg, size = size)\n",
    "    \n",
    "    return pc, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1113/1113 [29:03<00:00,  1.57s/it]\n"
     ]
    }
   ],
   "source": [
    "pcs, labels = [], []\n",
    "means_and_stds = []\n",
    "for file in tqdm(glob.glob('data/HCP_1200/*')):\n",
    "    segment = file+'/T1w/aparc+aseg.nii.gz'\n",
    "    intensity = file+'/T1w/T1w_acpc_dc_restore_brain.nii.gz'\n",
    "    pc, label = grey_filename_to_pc_and_labels(intensity, segment, \n",
    "                                  size = SIZE)\n",
    "    pc = np.array(pc.detach(),dtype = float)\n",
    "    means_and_stds.append([pc.mean(0), pc.std(0)])\n",
    "    pcs.append(pc)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_labels = [np.array(0)]*len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = np.array([x[1] for x in means_and_stds[test_idx:]]).mean(0)\n",
    "mean = np.array([x[0] for x in means_and_stds[test_idx:]]).mean(0)\n",
    "TEST_DATA_INDEXES = list(range(test_idx))\n",
    "pcs_test,labels_test, sc_labels_test = [(pcs[i]-mean)/std for i in TEST_DATA_INDEXES]*UPSAMPLE_RATE,[labels[i] for i in TEST_DATA_INDEXES]*UPSAMPLE_RATE,[sc_labels[i] for i in TEST_DATA_INDEXES]*UPSAMPLE_RATE\n",
    "pcs_train,labels_train, sc_labels_train = [(pcs[i]-mean)/std for i in range(len(pcs)) if i not in TEST_DATA_INDEXES]*UPSAMPLE_RATE, [labels[i] for i in range(len(pcs)) if i not in TEST_DATA_INDEXES]*UPSAMPLE_RATE, [sc_labels[i] for i in range(len(pcs)) if i not in TEST_DATA_INDEXES]*UPSAMPLE_RATE\n",
    "\n",
    "data_test = (pcs_test,labels_test, sc_labels_test)\n",
    "data_train = (pcs_train,labels_train, sc_labels_train)\n",
    "with open(f'data/BrainData/test_data{POSTFIX}.pkl', 'wb') as f:\n",
    "    pickle.dump(data_test, f)\n",
    "with open(f'data/BrainData/trainval_data{POSTFIX}.pkl', 'wb') as f:\n",
    "    pickle.dump(data_train, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
